{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abec157",
   "metadata": {},
   "source": [
    "# LZW Encoding\n",
    "\n",
    "This notebook shows the use of the `lzw_encode` and `lzw_decode` methods in `slz`. There is both a functional implementation and an object-oriented (stateful) implementation.\n",
    "\n",
    "\n",
    "### Encoding\n",
    "The encoding function `lzw_decode` has the following signature\n",
    "\n",
    "\n",
    "```python\n",
    "def lzw_encode(data: Union[str, bytes]) -> str:\n",
    "```\n",
    "\n",
    "In reality, the `str` return is really just a byte stream returned from the encoder. It almost always makes sense to do `b = lzw_encode(data).encode(\"utf-8\")`. The reason the return type is `str` rather than `bytes` is to do with how bytes work in Python and what is possible with `pybind11`. See for example [https://github.com/pybind/pybind11/issues/1236]. \n",
    "\n",
    "The signature in the underlying implementation is \n",
    "\n",
    "```c++\n",
    "std::stringstream lzw_encode(const std::string_view input);\n",
    "```\n",
    "\n",
    "Because the return type is strictly `str` we need to explicitly convert to `bytes` if a byte stream is required by doing ```enc_out.encode(\"utf-8\")```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43099d3e",
   "metadata": {},
   "source": [
    "## Encoding format.\n",
    "\n",
    "The output of the encoder is a byte stream containing the compressed bytes. To be able to recover the stream information correctly when decoding some header information is prepended to the data. The data stream consists of\n",
    "symbols that vary in size from 2-4 bytes per symbol. At the start of the stream all symbols are 2 bytes. As the prefix tree gets longer it becomes possible to gain more compression by using a larger symbol that represents a longer prefix. At some point the stream will contain symbols that are all 3 bytes long, and then even later all symbols will be 4 bytes long. When decoding the stream we need to know at which point the size of the symbols changes. We encode this information in a 12 byte header at the start of the stream\n",
    "\n",
    "The header format is \n",
    "\n",
    "- (__4 bytes__) - offset in stream where the first 24-bit code is. If this is zero there are no 24-bit codes\n",
    "- (__4 bytes__) - offset in stream where the first 32-bit code is. If this is zero there are no 32-bit codes.\n",
    "- (__4 bytes__) - total number of codes in the stream.\n",
    "\n",
    "The byte at offset 12 is the first byte in the data stream and is part of a 2-byte symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb682b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80811594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: hack - need to pip install package to avoid this?\n",
    "import os\n",
    "os.chdir(\"..\")    # cant load slz as a module from the notebooks directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cce314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input string  : 9\n",
      "Length of output string : 24\n",
      "bytes: b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x01\\x00\\x00b\\x00a\\x00\\x00\\x01\\x01\\x01a\\x00\\x04\\x01'\n"
     ]
    }
   ],
   "source": [
    "from slz import lzw_encode      # import the functional encoder\n",
    "\n",
    "# We start with the example from the unit test \n",
    "test_input = \"babaabaaa\"\n",
    "\n",
    "encoded = lzw_encode(test_input)\n",
    "enc_bytes = encoded.encode(\"utf-8\")\n",
    "\n",
    "print(f\"Length of input string  : {len(test_input.encode('utf-8'))}\")\n",
    "print(f\"Length of output string : {len(enc_bytes)}\")\n",
    "print(f\"bytes: {enc_bytes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2ab2e",
   "metadata": {},
   "source": [
    "Note that the output is longer than the input. This is often the case in general with compression - significant compression is achieved in the limit but often not for small inputs. In this specific case though some of the overhead is in the header itself. The first 12 bytes provide information for decoding. In this example the header is longer than the original string, and actually contains relatively little information. If we skip the first 12 bytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c0523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes: b'\\x00b\\x00a\\x00\\x00\\x01\\x01\\x01a\\x00\\x04\\x01'\n"
     ]
    }
   ],
   "source": [
    "print(f\"bytes: {enc_bytes[11:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b3919",
   "metadata": {},
   "source": [
    "We can decode a stream with this header using `lzw_decode`. This accepts a byte stream that is expected to have the header format described above, followed by a byte stream of compressed bytes. The signature for `lzw_decode` is\n",
    "\n",
    "```python\n",
    "def lzw_decode(data: bytes) -> str:\n",
    "```\n",
    "\n",
    "The underlying representation accepts a `std::stringstream` but is wrapped to accept a `const std::string&`. The function accepts `str` or `bytes`, but a `str` formatted for display may not preserve the header information correctly. \n",
    "\n",
    "```c++\n",
    "std::string lzw_decode(const std::string& data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab11060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input string  : 24\n",
      "Length of output string : 9\n",
      "str: babaabaaa\n"
     ]
    }
   ],
   "source": [
    "from slz import lzw_decode\n",
    "\n",
    "dec_out = lzw_decode(enc_bytes)\n",
    "\n",
    "print(f\"Length of input string  : {len(enc_bytes)}\")\n",
    "print(f\"Length of output string : {len(dec_out)}\")\n",
    "print(f\"str: {dec_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480477f8",
   "metadata": {},
   "source": [
    "### Encoding a stream from a file \n",
    "\n",
    "Notice that the compression ration on small inputs is very poor. At minimum the size of the stream needs to be logn enoguh to amortize the length of the header. Additionally, we tend to get better compression performance when we have a deep prefix tree. Constructing a deep prefix tree requires us to consume more symbols. In the following cells we explore compressing longer streams.\n",
    "\n",
    "To avoid getting psy-op'd on copyright issues we use the collected works of Shakespear from Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ecceb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " COMEDY OF ERRORS\n",
      "    THE TRAGEDY OF CORIOLANUS\n",
      "    CYMBELINE\n",
      "    THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\n",
      "    THE FIRST PART OF KING HENRY THE FOURTH\n",
      "    THE SECOND PART OF KING HENRY THE FOURTH\n",
      "    THE LIFE OF KING HENRY THE FIFTH\n",
      "    THE FIRST PART OF HENRY THE SIXTH\n",
      "    THE SECOND PART OF KING HENRY THE SIXTH\n",
      "    THE THIRD PART OF KING HENRY THE SIXTH\n",
      "    KING HENRY THE EIGHTH\n",
      "    THE LIFE AND DEATH OF KING JOHN\n",
      "    THE TRAGEDY OF JULIUS CAESAR\n",
      "    THE TRAGEDY OF KING LEAR\n",
      "    LOVE’S LABOUR’S LOST\n",
      "    THE TRAGEDY OF MACBETH\n",
      "    MEASURE FOR MEASURE\n",
      "    THE MERCHANT OF VENICE\n",
      "    THE MERRY WIVES OF WINDSOR\n",
      "    A MIDSUMMER NIGHT’S DREAM\n",
      "    MUCH ADO ABOUT NOTHING\n",
      "    THE TRAGEDY OF OTHELLO, THE MOOR OF VENICE\n",
      "    PERICLES, PRINCE OF TYRE\n",
      "    KING RICHARD THE SECOND\n",
      "    KING RICHARD THE THIRD\n",
      "    THE TRAGEDY OF ROMEO AND JULIET\n",
      "    THE TAMING OF THE SHREW\n",
      "    THE TEMPEST\n",
      "    THE LIFE OF TIMON OF ATHENS\n",
      "    THE TRAGEDY OF TITUS ANDRONICUS\n",
      "    TROILUS AND CRESSIDA\n",
      "    TWELFTH NIGHT; OR, WHAT YOU WILL\n",
      "    THE TW\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "input_filename = \"test/shakespear.txt\"\n",
    "\n",
    "with open(input_filename, \"r\") as fp:\n",
    "    text = fp.read()\n",
    "    #text = \"\".join(fp.readlines())\n",
    "    \n",
    "substr = text[1024:2048]\n",
    "print(type(substr))\n",
    "print(substr)\n",
    "print(len(substr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda7551",
   "metadata": {},
   "source": [
    "We encode the string using `lzw_encode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "249a7ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd1 in position 8: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#enc = lzw_encode(str(substr))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m enc \u001b[38;5;241m=\u001b[39m \u001b[43mlzw_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(enc))\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd1 in position 8: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "\n",
    "#enc = lzw_encode(str(substr))\n",
    "enc = lzw_encode(substr.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "print(len(enc))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
